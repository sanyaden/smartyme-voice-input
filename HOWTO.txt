> —É –Ω–∞—Å —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–æ–±—ã–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥–∞ –Ω–∞ flutter –¥–ª—è ios —ã android. –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º webview –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏, –∫–∞–∫ –∏–º –¥–æ–¥–∞—Ç—å —Ç–∞–∫–æ–π –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º?

‚è∫ –û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞ –≤ Flutter WebView –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥–µ –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤. –í–æ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ:

  üé§ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞

  1. Flutter Side (Dart –∫–æ–¥)

  // pubspec.yaml
  dependencies:
    flutter_inappwebview: ^6.0.0
    speech_to_text: ^6.6.0
    flutter_tts: ^3.8.5
    permission_handler: ^11.0.2

  // voice_webview_controller.dart
  class VoiceWebViewController {
    InAppWebViewController? webViewController;
    SpeechToText speechToText = SpeechToText();
    FlutterTts flutterTts = FlutterTts();
    bool isConversationalMode = false;

    // Initialize voice functionality
    Future<void> initializeVoice() async {
      await speechToText.initialize();
      await flutterTts.setLanguage("en-US");
      await flutterTts.setSpeechRate(0.52);
      await flutterTts.setVolume(0.9);
    }

    // JavaScript handlers for WebView communication
    void addJavaScriptHandlers(InAppWebViewController controller) {
      controller.addJavaScriptHandler(
        handlerName: 'speechBridge',
        callback: (args) async {
          final command = args[0]['command'];
          switch (command) {
            case 'toggleConversationalMode':
              await toggleConversationalMode();
              break;
            case 'speakIfEnabled':
              await speakText(args[0]['text']);
              break;
          }
        }
      );
    }

    // Toggle conversational mode
    Future<void> toggleConversationalMode() async {
      if (!await Permission.microphone.isGranted) {
        await Permission.microphone.request();
      }

      isConversationalMode = !isConversationalMode;

      if (isConversationalMode) {
        await startListening();
      } else {
        await speechToText.stop();
        await flutterTts.stop();
      }

      // Notify WebView
      webViewController?.evaluateJavascript(source: '''
        if (window.nativeVoice && window.nativeVoice.onModeChanged) {
          window.nativeVoice.onModeChanged($isConversationalMode);
        }
      ''');
    }

    // Start speech recognition
    Future<void> startListening() async {
      await speechToText.listen(
        onResult: (result) {
          if (result.finalResult) {
            sendVoiceToWebView(result.recognizedWords);
          } else {
            // Send interim results
            webViewController?.evaluateJavascript(source: '''
              if (window.nativeVoice && window.nativeVoice.onInterimResult) {
                window.nativeVoice.onInterimResult('${result.recognizedWords}');
              }
            ''');
          }
        },
        listenOptions: SpeechListenOptions(
          listenMode: ListenMode.confirmation,
          cancelOnError: false,
          pauseFor: Duration(seconds: 2), // Quick timeout
          enableHapticFeedback: true,
        )
      );
    }

    // Send voice message to WebView chat
    Future<void> sendVoiceToWebView(String transcript) async {
      webViewController?.evaluateJavascript(source: '''
        (function() {
          // Find chat input and submit voice message
          const message = '$transcript';

          // Method 1: Direct API call (like your current iOS implementation)
          fetch('/api/chat/message', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              message: message,
              userId: getUrlParam('user_id'),
              sessionId: sessionStorage.getItem('sessionId'),
              entryPoint: 'flutter_voice'
            })
          }).then(response => response.json())
            .then(data => {
              // Add message to chat UI
              if (window.addMessageToChat) {
                window.addMessageToChat('user', message);
                window.addMessageToChat('assistant', data.response);
              }

              // Speak AI response
              if (window.flutter_inappwebview) {
                window.flutter_inappwebview.callHandler('speechBridge', {
                  command: 'speakIfEnabled',
                  text: data.response
                });
              }
            });
        })();
      ''');
    }

    // Speak text using TTS
    Future<void> speakText(String text) async {
      if (isConversationalMode) {
        await flutterTts.speak(text);

        // Restart listening after TTS finishes
        flutterTts.setCompletionHandler(() async {
          if (isConversationalMode) {
            await Future.delayed(Duration(milliseconds: 500));
            await startListening();
          }
        });
      }
    }
  }

  2. WebView Setup

  // main_webview.dart
  class MainWebView extends StatefulWidget {
    @override
    _MainWebViewState createState() => _MainWebViewState();
  }

  class _MainWebViewState extends State<MainWebView> {
    final VoiceWebViewController voiceController = VoiceWebViewController();
    InAppWebViewController? webViewController;

    @override
    void initState() {
      super.initState();
      voiceController.initializeVoice();
    }

    @override
    Widget build(BuildContext context) {
      return Scaffold(
        body: SafeArea(
          child: InAppWebView(
            initialUrlRequest: URLRequest(
              url: WebUri("http://your-server.com/webview?user_id=123")
            ),
            onWebViewCreated: (controller) {
              webViewController = controller;
              voiceController.webViewController = controller;
              voiceController.addJavaScriptHandlers(controller);
            },
            onLoadStop: (controller, url) async {
              // Inject voice bridge JavaScript
              await controller.evaluateJavascript(source: '''
                window.flutter_voice = {
                  isSupported: true,
                  toggleConversationalMode: function() {
                    window.flutter_inappwebview.callHandler('speechBridge', {
                      command: 'toggleConversationalMode'
                    });
                  },
                  speak: function(text) {
                    window.flutter_inappwebview.callHandler('speechBridge', {
                      command: 'speakIfEnabled',
                      text: text
                    });
                  }
                };

                // Add voice button to existing UI
                setTimeout(() => {
                  const voiceButton = document.createElement('button');
                  voiceButton.innerHTML = 'üé§';
                  voiceButton.style.cssText = `
                    position: fixed;
                    bottom: 20px;
                    right: 20px;
                    width: 60px;
                    height: 60px;
                    border-radius: 30px;
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    border: none;
                    font-size: 24px;
                    color: white;
                    cursor: pointer;
                    z-index: 1000;
                    box-shadow: 0 4px 15px rgba(0,0,0,0.2);
                  `;
                  voiceButton.onclick = () => window.flutter_voice.toggleConversationalMode();
                  document.body.appendChild(voiceButton);
                }, 1000);
              ''');
            },
          ),
        ),
      );
    }
  }

  3. Android-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è

  <!-- android/app/src/main/AndroidManifest.xml -->
  <uses-permission android:name="android.permission.RECORD_AUDIO" />
  <uses-permission android:name="android.permission.INTERNET" />
  <uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS" />

  4. iOS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è

  <!-- ios/Runner/Info.plist -->
  <key>NSMicrophoneUsageDescription</key>
  <string>This app needs microphone access for voice chat functionality.</string>
  <key>NSSpeechRecognitionUsageDescription</key>
  <string>This app needs speech recognition for voice commands.</string>

  üöÄ –ü–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è:

  –≠—Ç–∞–ø 1: –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

  1. –î–æ–±–∞–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ pubspec.yaml
  2. –°–æ–∑–¥–∞—Ç—å VoiceWebViewController
  3. –î–æ–±–∞–≤–∏—Ç—å JavaScript handlers –≤ WebView

  –≠—Ç–∞–ø 2: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞

  1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å speech-to-text
  3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å text-to-speech

  –≠—Ç–∞–ø 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º WebView

  1. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≥–æ–ª–æ—Å–∞
  2. –î–æ–±–∞–≤–∏—Ç—å –∫–Ω–æ–ø–∫—É –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å API —á–∞—Ç–∞

  –≠—Ç–∞–ø 4: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –ø–æ–ª–∏—Ä–æ–≤–∫–∞

  1. –£–ª—É—á—à–∏—Ç—å UX (–∞–Ω–∏–º–∞—Ü–∏–∏, –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
  2. –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
  3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

  üéØ –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ç–∞–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:

  - –ë—ã—Å—Ç—Ä–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –≤–µ–±-–∫–æ–¥–µ
  - –ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ—Å—Ç—å: –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ iOS –∏ Android
  - –ù–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—Ç–∏–≤–Ω—ã–µ API –¥–ª—è –≥–æ–ª–æ—Å–∞
  - –ì–∏–±–∫–æ—Å—Ç—å: –õ–µ–≥–∫–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏

  –•–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã —è –ø–æ–º–æ–≥ —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –∫–∞–∫–æ–≥–æ-—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç—Ç–∞–ø–∞?
